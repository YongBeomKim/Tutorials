{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 1 절  Tensor의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "numerical computing by Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    파이썬에서 가장 대중적인 모듈 (Numpy, Pandas, Scipy, matplotlib..)중 하나로, 파이썬의 느린 '연산'을 보완하는 모듈이다.\n",
    "    이는 C++ 모듈을 사용하여 숫자와 Matrix 연산 함으로써, 최대 25배 속도 향상을 보여준다 (그만큼 파이썬 기본연산이 느리다는 방증\n",
    "    이기도 하다)\n",
    "\n",
    "    기본적인 표 편집 및 자료수집 및 편집 연산시 Pandas 와 함께 쓰이는데, \n",
    "    Numpy 는 엑셀 셀 내부의 연산함수 ( = sum() , = if()) 기능을 담당하고\n",
    "    Pandas 는 엑셀 아웃라인에서 작동하는 메뉴버튼 ('파일불러오기', '표편집', '피봇테이블') 기능을 구현하며,\n",
    "    pandas 를 실행할 때에도 옵션역활로써 Numpy를 석어서 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "numerical computing by Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    머신러닝 공개 모듈 중 하나로(공짜다)\n",
    "    넘파이(NumPy) 정도를 제외하고는 거의 의존성이 없고, 텐서 연산을 위한 C++ 코드를 제외하고는 대부분 파이썬으로 구현이 되어 있어서,\n",
    "    다른 파이썬 모듈 (자동으로 그래디언트를 계산해 주는 Autograd, NumPy/SciPy) 과의 뛰어난 호환성을 보여주고\n",
    "    깔끔한 코드 로 구현이 가능하다\n",
    "    \n",
    "    Nural Network 의 그래프를 정의하고 실행하는 다른 머신러닝 (tensorflow 등) 모듈과 달리, \n",
    "    작업자가 코딩하는 대로 그래프가 점진적으로 만들어 나아감으로써 작업 과정 중간에도 데이터의 내용을 확인하며\n",
    "    가장 적합한 머신러닝 알고리즘을 찾아가며 이를 적용하고 분석함에 용이하다.\n",
    "    \n",
    "    (출처 : https://tensorflow.blog/2017/01/23/pytorch-new-cool-dl-library/ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 배열 생성\n",
    "<p>Tensor (어떻게 바라보아도 그 본질이 변하지 않는 것)</p></br>\n",
    "분석하고자 하는 데이터의 형태로써, 일반적인 배열(Matrix) 형태를 띈다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(2) numpy 의 ndarray 와 pytorch 의 tensor </p></br>\n",
    "1) numpy : n 차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# numpy 생성\n",
    "data = [ 1,2,3,4,5]\n",
    "data = np.array(data)\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# numpy 배열생성\n",
    "data = np.arange(20)\n",
    "data = data.reshape(5,4)\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) pytorch : tensor (N차원의 매트릭스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy의 ndarray와 유사\n",
    "# pytorch는 아래와 같이 7가지 CPU 텐서 타입과 8가지 GPU 텐서 타입을 정의내리고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pytorch는 디폴트 텐서를 torch.FloatTensor로 세팅한다.\n",
    "# 파이썬의 리스트 또는 시퀀스(자동번호 발생기 range()) 를 활용해서 생성 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.FloatTensor()\n",
    "torch.FloatTensor([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3\n",
       " 4  5  6\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.FloatTensor()\n",
    "torch.FloatTensor([ [1,2,3], [4,5,6] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-4.6117e+27  4.5595e-41  3.3090e+12\n",
       " 3.0917e-41  4.4842e-44  0.0000e+00\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 3 배열의 랜덤 텐서를 생성\n",
    "torch.FloatTensor(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(3) numpy 와 tensor 상호 변환</p></br>\n",
    "1) numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy 객체 생성\n",
    "ar = np.arange(20).reshape(5,4)\n",
    "ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) numpy --> tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3\n",
       "  4   5   6   7\n",
       "  8   9  10  11\n",
       " 12  13  14  15\n",
       " 16  17  18  19\n",
       "[torch.LongTensor of size 5x4]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy --> tensor \n",
    "x = torch.from_numpy(ar)  # default 값 : LongTensor 로 치환\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. in-place / Out-of-place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(1) 텐서의 생성</p></br>\n",
    "먼저 (5X7)의 사이즈를 가지는 텐서를 생성해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 5 \n",
       "-4.6117e+27  4.5595e-41 -4.6117e+27  4.5595e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  2.7045e-43\n",
       "-4.6118e+27  4.5595e-41 -4.6118e+27  4.5595e-41  8.4878e+11  3.0917e-41\n",
       "\n",
       "Columns 6 to 6 \n",
       " 0.0000e+00\n",
       " 0.0000e+00\n",
       " 0.0000e+00\n",
       " 0.0000e+00\n",
       " 0.0000e+00\n",
       "[torch.FloatTensor of size 5x7]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "a = torch.FloatTensor(5,7)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean = 0, var = 1 인 정규분포를 갖는 랜덤추출 텐서를 생성해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2540  1.7587 -0.1568  0.7781 -0.1844 -0.9666  1.3026\n",
      " 0.0241  0.1427 -0.6117 -1.1298  1.0834 -1.7028  0.8497\n",
      "-0.1046  0.2295 -0.7851  0.4246 -0.6619  0.1709  0.8972\n",
      "-0.6241 -0.9259  0.9425 -0.0918 -0.0381 -0.6116  0.2824\n",
      " 0.8369 -0.4727  0.8196 -0.4545 -0.6154 -0.4111 -0.4724\n",
      "[torch.FloatTensor of size 5x7]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5,7)\n",
    "print(a)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(2) In-place / Out-of-place</p></br>\n",
    "Pytorch에서는 텐서에 영향을 미치는 방향에 따라 in-place 와 out-of-place의 개념이 존재한다\n",
    "-  http://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html?highlight=narrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (https://stackoverflow.com/questions/35769944/manipulating-matrix-elements-in-tensorflow)\n",
    "    텐서플로는 tf.scatter_update() 등으로 객체값을 변환 후 tf.initialize_all_variables() 로 초기화 명령을\n",
    "    시행해야만 데이터가 갱신된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2540  1.7587 -0.1568  0.7781 -0.1844 -0.9666  1.3026\n",
       " 0.0241  0.1427 -0.6117 -1.1298  1.0834 -1.7028  0.8497\n",
       "-0.1046  0.2295 -0.7851  0.4246 -0.6619  0.1709  0.8972\n",
       "-0.6241 -0.9259  0.9425 -0.0918 -0.0381 -0.6116  0.2824\n",
       " 0.8369 -0.4727  0.8196 -0.4545 -0.6154 -0.4111 -0.4724\n",
       "[torch.FloatTensor of size 5x7]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    파이썬에서 언더스코어(_)는 다음과 같은 상황에서 사용되는데 크게 5가지의 경우가 있다.\n",
    "\n",
    "    1.인터프리터(Interpreter)에서 마지막 값을 저장할 때\n",
    "    2.값을 무시하고 싶을 때 (흔히 “I don’t care”라고 부른다.)\n",
    "    3.변수나 함수명에 특별한 의미 또는 기능을 부여하고자 할 때\n",
    "    4.국제화(Internationalization, i18n)/지역화(Localization, l10n) 함수로써 사용할 때\n",
    "    5.숫자 리터럴값의 자릿수 구분을 위한 구분자로써 사용할 때\n",
    "    (출처 : https://mingrammer.com/underscore-in-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.5000  3.5000  3.5000  3.5000  3.5000  3.5000  3.5000\n",
       " 3.5000  3.5000  3.5000  3.5000  3.5000  3.5000  3.5000\n",
       " 3.5000  3.5000  3.5000  3.5000  3.5000  3.5000  3.5000\n",
       " 3.5000  3.5000  3.5000  3.5000  3.5000  3.5000  3.5000\n",
       " 3.5000  3.5000  3.5000  3.5000  3.5000  3.5000  3.5000\n",
       "[torch.FloatTensor of size 5x7]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fill_(3.5)  # '_' (underscore) 새로운 값으로 채운다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 7.5000  7.5000  7.5000  7.5000  7.5000  7.5000  7.5000\n",
       " 7.5000  7.5000  7.5000  7.5000  7.5000  7.5000  7.5000\n",
       " 7.5000  7.5000  7.5000  7.5000  7.5000  7.5000  7.5000\n",
       " 7.5000  7.5000  7.5000  7.5000  7.5000  7.5000  7.5000\n",
       " 7.5000  7.5000  7.5000  7.5000  7.5000  7.5000  7.5000\n",
       "[torch.FloatTensor of size 5x7]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(4.0)    # 텐서값을 추가한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    언더스코어(_) 는 모든 함수에 있어서 일괄 적용되지 않는다.\n",
    "    .narrow() 함수(operation)는 존재해도 .narrow_ 는 존재하지 않고,\n",
    "    반대로 .fill_() 는 존재해도 .fill() 는 존재하지 않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 인덱싱 (indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = np.arange(20).reshape(5,4)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3\n",
       "  4   5   6   7\n",
       "  8   9  10  11\n",
       " 12  13  14  15\n",
       " 16  17  18  19\n",
       "[torch.LongTensor of size 5x4]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(ar)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.LongTensor of size 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제로 인덱싱이 가능함 ( 0 번 인덱스 값을 갖는 x의 value 들을 출력)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1] # index 0 , col_num 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2,1] # index 2 , col_num 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  2\n",
       "  6\n",
       " 10\n",
       " 14\n",
       " 18\n",
       "[torch.LongTensor of size 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,2] # index all , col_num 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1   2\n",
       "  5   6\n",
       "  9  10\n",
       " 13  14\n",
       " 17  18\n",
       "[torch.LongTensor of size 5x2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1:3] # index all, col_num 1,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. index\\_add\\_\n",
    "원본 'x 텐서'와 't 텐서'의 값을 더할 때, 별도의 인덱스값을 기준으로 더한다. (matrix합 연산이 아닌 같은 위상의 값의 합) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([ [1,1,1], [1,1,1], [1,1,1] ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([ [1,2,3], [4,5,6], [7,8,9]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 2\n",
       " 1\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.LongTensor([0, 2, 1])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  2   3   4\n",
       "  8   9  10\n",
       "  5   6   7\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.index_add_( dim(int), index(LongTensor), tensor(Tensor) )\n",
    "# x - 원본텐서\n",
    "# dim(int) - 연산 기준이 되는 인덱스index(LongTensor) 의 차원을 정의 (0 : 인덱스 값이 1차원일 떄) (1 ,2 ,3 : 계층적 인덱스일 떄) \n",
    "# index(LongTensor) - 기준 인덱스\n",
    "# tensor(Tensor) - 연산 대상 값\n",
    "x.index_add_(0, index, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 마스킹(masking)\n",
    "[True, False, True, True....] 으로 구성, 'True'의 index 와 동일한 index의 value 만 연산에 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([ [1,1,1], [1,1,1], [1,1,1] ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3\n",
       "  4   5   6   7\n",
       "  8   9  10  11\n",
       " 12  13  14  15\n",
       " 16  17  18  19\n",
       "[torch.LongTensor of size 5x4]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy 객체 생성\n",
    "x = np.arange(20).reshape(5,4)\n",
    "x = torch.from_numpy(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  0  0  0\n",
       " 0  1  0  0\n",
       " 0  0  1  0\n",
       " 0  0  0  1\n",
       " 0  1  0  0\n",
       "[torch.ByteTensor of size 5x4]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ByteTensor([ [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1], [0,1,0,0] ])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0\n",
       "  5\n",
       " 10\n",
       " 15\n",
       " 17\n",
       "[torch.LongTensor of size 5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 x 데이터 중 mask 의 1 과 동일한 인덱스의 value 들만 출력\n",
    "out = torch.masked_select(x, mask)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 조이닝(Joining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    <pandas>\n",
    "    frames = [df1, df2, df3]\n",
    "    result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3  4\n",
      " 5  6  7\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      "-2 -3 -4\n",
      "-5 -6 -7\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성\n",
    "a = torch.FloatTensor([[2,3,4],[5,6,7]])\n",
    "b = torch.FloatTensor([[-2,-3,-4],[-5,-6,-7]])\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3  4\n",
      " 5  6  7\n",
      "-2 -3 -4\n",
      "-5 -6 -7\n",
      "[torch.FloatTensor of size 4x3]\n",
      " \n",
      " 2  3  4 -2 -3 -4\n",
      " 5  6  7 -5 -6 -7\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1개의 텐서로 결합\n",
    "c1 = torch.cat([a, b],dim=0)  # 0 : 컬럼을 기준으로 연결 (concatenate)\n",
    "c2 = torch.cat([a, b],dim=1)  # 1 : row를 기준으로 연결 (concatenate)\n",
    "print(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  2  3  4\n",
       "  5  6  7\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2  3  4\n",
       "  5  6  7\n",
       "\n",
       "(2 ,.,.) = \n",
       "  2  3  4\n",
       "  5  6  7\n",
       "\n",
       "(3 ,.,.) = \n",
       "  2  3  4\n",
       "  5  6  7\n",
       "[torch.FloatTensor of size 4x2x3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 index를 갖는 1개의 텐서로 결합\n",
    "# dim = 0 : 결합갯수가 인덱스 기준\n",
    "c0_stack = torch.stack( [a,a,a,a], dim=0)\n",
    "c0_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c0_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3  4\n",
       " 5  6  7\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0_stack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  2  3  4\n",
       "  2  3  4\n",
       "  2  3  4\n",
       "  2  3  4\n",
       "\n",
       "(1 ,.,.) = \n",
       "  5  6  7\n",
       "  5  6  7\n",
       "  5  6  7\n",
       "  5  6  7\n",
       "[torch.FloatTensor of size 2x4x3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 index를 갖는 1개의 텐서로 결합\n",
    "# dim = 1 : 자료의 형태가 인덱스 기준\n",
    "c1_stack = torch.stack( [a,a,a,a], dim=1)\n",
    "c1_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. 슬라이싱(Slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3  4\n",
      " 5  6  7\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      "-2 -3 -4\n",
      "-5 -6 -7\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성\n",
    "a = torch.FloatTensor([[2,3,4],[5,6,7]])\n",
    "b = torch.FloatTensor([[-2,-3,-4],[-5,-6,-7]])\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3  4\n",
      " 5  6  7\n",
      "-2 -3 -4\n",
      "-5 -6 -7\n",
      "[torch.FloatTensor of size 4x3]\n",
      " \n",
      " 2  3  4 -2 -3 -4\n",
      " 5  6  7 -5 -6 -7\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1개의 텐서로 결합\n",
    "c1 = torch.cat([a, b],dim=0)  # 0 : 컬럼을 기준으로 연결 (concatenate)\n",
    "c2 = torch.cat([a, b],dim=1)  # 1 : row를 기준으로 연결 (concatenate)\n",
    "print(c1,c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk\n",
    "정확한 분할 등분, 정확히 나뉘지 않으면 오류가 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chunk : 덩어리\n",
    "# torch.chunk(원본, 덩어리 갯수, 분할기준)\n",
    "# 정확히 데이터와 분할기준이 맞아야 작동\n",
    "x_1, x_2 = torch.chunk(c1,2,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3  4\n",
       " 5  6  7\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk : 덩어리\n",
    "# torch.chunk(원본, 덩어리 갯수, 분할기준)\n",
    "x_1, x_2, x_3 = torch.chunk(c1,3,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 5\n",
       "-2\n",
       "-5\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split\n",
    "물리적으로 나뉜다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.split(원본, 분할 갯수, 분할기준)\n",
    "x_1, x_2 = torch.split(c1,2,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3  4\n",
       " 5  6  7\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 물리적으로 나눈다\n",
    "x_1, x_2 = torch.split(c1,2,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  3\n",
       " 5  6\n",
       "-2 -3\n",
       "-5 -6\n",
       "[torch.FloatTensor of size 4x2]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4\n",
       " 7\n",
       "-4\n",
       "-7\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0   1   2\n",
       "   3   4   5\n",
       "   6   7   8\n",
       "   9  10  11\n",
       "\n",
       "(1 ,.,.) = \n",
       "  12  13  14\n",
       "  15  16  17\n",
       "  18  19  20\n",
       "  21  22  23\n",
       "\n",
       "(2 ,.,.) = \n",
       "  24  25  26\n",
       "  27  28  29\n",
       "  30  31  32\n",
       "  33  34  35\n",
       "[torch.LongTensor of size 3x4x3]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = np.arange(36).reshape(3,4,3)\n",
    "x1 = torch.from_numpy(ar)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25\n",
       " 26\n",
       " 27\n",
       " 28\n",
       " 29\n",
       " 30\n",
       " 31\n",
       " 32\n",
       " 33\n",
       " 34\n",
       " 35\n",
       "[torch.LongTensor of size 36]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x1.view(-1)\n",
    "print(x2.size())\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     7     8     9    10    11\n",
       "   12    13    14    15    16    17    18    19    20    21    22    23\n",
       "   24    25    26    27    28    29    30    31    32    33    34    35\n",
       "[torch.LongTensor of size 3x12]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x1.view(3,-1)\n",
    "print(x2.size())\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3   4   5\n",
       "  6   7   8   9  10  11\n",
       " 12  13  14  15  16  17\n",
       " 18  19  20  21  22  23\n",
       " 24  25  26  27  28  29\n",
       " 30  31  32  33  34  35\n",
       "[torch.LongTensor of size 6x6]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x1.view(6,-1)\n",
    "print(x2.size())\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2\n",
       "    3     4     5\n",
       "    6     7     8\n",
       "    9    10    11\n",
       "   12    13    14\n",
       "   15    16    17\n",
       "   18    19    20\n",
       "   21    22    23\n",
       "   24    25    26\n",
       "   27    28    29\n",
       "   30    31    32\n",
       "   33    34    35\n",
       "[torch.LongTensor of size 12x3]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x1.view(12,-1)\n",
    "print(x2.size())\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 12, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0\n",
       "   1\n",
       "   2\n",
       "   3\n",
       "   4\n",
       "   5\n",
       "   6\n",
       "   7\n",
       "   8\n",
       "   9\n",
       "  10\n",
       "  11\n",
       "\n",
       "(1 ,.,.) = \n",
       "  12\n",
       "  13\n",
       "  14\n",
       "  15\n",
       "  16\n",
       "  17\n",
       "  18\n",
       "  19\n",
       "  20\n",
       "  21\n",
       "  22\n",
       "  23\n",
       "\n",
       "(2 ,.,.) = \n",
       "  24\n",
       "  25\n",
       "  26\n",
       "  27\n",
       "  28\n",
       "  29\n",
       "  30\n",
       "  31\n",
       "  32\n",
       "  33\n",
       "  34\n",
       "  35\n",
       "[torch.LongTensor of size 3x12x1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x1.view(3,12,-1)\n",
    "print(x2.size())\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "narrow received an invalid combination of arguments - got (), but expected (int dimension, int start, int length)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-da783392a1c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: narrow received an invalid combination of arguments - got (), but expected (int dimension, int start, int length)"
     ]
    }
   ],
   "source": [
    "a.narrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
