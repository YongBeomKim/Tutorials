{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Sigmoid 함수를 활용한 학습모형 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbd8c0b90d8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2\n",
       " 2  3\n",
       " 3  1\n",
       " 4  3\n",
       " 5  3\n",
       " 6  2\n",
       "[torch.FloatTensor of size 6x2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]], dtype=np.float32)\n",
    "y_data = np.array([[0], [0], [0], [1], [1], [1]], dtype=np.float32)\n",
    "X = Variable(torch.from_numpy(x_data))\n",
    "Y = Variable(torch.from_numpy(y_data))\n",
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 6x1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypothesis using sigmoid\n",
    "# [텐서플로] tf.div(1., 1. + tf.exp(tf.matmul(X, W))) : 중간에 행렬곱 연산을 직접 입력해야 한다.\n",
    "linear = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear, sigmoid)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 1.34154904]\n",
      "2000 [ 0.33371782]\n",
      "4000 [ 0.25374085]\n",
      "6000 [ 0.20293365]\n",
      "8000 [ 0.1686267]\n",
      "10000 [ 0.14417094]\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    # cost/loss function\n",
    "    cost = -(Y * torch.log(hypothesis) + (1 - Y)\n",
    "             * torch.log(1 - hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 2000 == 0:\n",
    "        print(step, cost.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[ 0.02853693]\n",
      " [ 0.15574944]\n",
      " [ 0.2941438 ]\n",
      " [ 0.78632414]\n",
      " [ 0.94264686]\n",
      " [ 0.98120463]] \n",
      "Correct (Y):  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "predicted = (model(X).data > 0.5).float()\n",
    "accuracy = (predicted == Y.data).float().mean()\n",
    "print(\"\\nHypothesis: \", hypothesis.data.numpy(), \"\\nCorrect (Y): \", predicted.numpy(), \"\\nAccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV를 활용한 Sigmoid 학습모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbd8c0b90d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.29411799  0.48743701  0.180328   -0.29292899  0.          0.00149028\n",
      "  -0.53117001 -0.0333333   0.        ]\n",
      " [ 0.          0.0854271   0.114754   -0.59596002  0.         -0.186289\n",
      "  -0.39453501 -0.63333303  1.        ]\n",
      " [-0.52941197  0.155779    0.180328    0.          0.         -0.13859899\n",
      "  -0.74551702 -0.166667    0.        ]\n",
      " [ 0.          0.52763802  0.344262   -0.21212099 -0.35697401  0.23695999\n",
      "  -0.83603799 -0.80000001  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('./Lecture/data-03-diabetes.csv',delimiter=',',dtype=np.float32)\n",
    "print(xy[::200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_data :\n",
      " [[-0.29411799  0.48743701  0.180328   -0.29292899  0.          0.00149028\n",
      "  -0.53117001 -0.0333333 ]]\n",
      "\n",
      "y_data :\n",
      " [[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      " {0.0, 1.0}\n",
      "\n",
      "x_data :  (759, 8) \n",
      "y_data :  (759, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "print('\\nx_data :\\n', x_data[:1])\n",
    "print('\\ny_data :\\n', y_data[:3], '\\n',set([y[0]  for y in y_data]))\n",
    "print('\\nx_data : ', x_data.shape, '\\ny_data : ', y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 파이토치서 분석 가능한 포맷으로 변환\n",
    "X = Variable(torch.from_numpy(x_data))\n",
    "Y = Variable(torch.from_numpy(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid함수를 활용한 가설 만들기\n",
    "linear = torch.nn.Linear(8, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear, sigmoid)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.63136256]\n",
      "2000 [ 0.54290104]\n",
      "4000 [ 0.50976342]\n",
      "6000 [ 0.49440202]\n",
      "8000 [ 0.48628604]\n",
      "10000 [ 0.48161238]\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #cost/loss 함수\n",
    "    cost = -(Y * torch.log(hypothesis) + (1-Y)\n",
    "               * torch.log(1-hypothesis)).mean()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 2000 == 0:\n",
    "        print(step, cost.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis ( 759 ) : [[ 0.41512308]\n",
      " [ 0.61203277]\n",
      " [ 0.7081036 ]\n",
      " [ 0.75963616]\n",
      " [ 0.72033864]\n",
      " [ 0.7712003 ]\n",
      " [ 0.3413842 ]\n",
      " [ 0.8460204 ]] \n",
      "Correct ( 759 )  : [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]] \n",
      "Accuracy :  0.764163372859025\n"
     ]
    }
   ],
   "source": [
    "# 학습 모델의 정확도(Accuracy) 측정 : 약 76% 정확도.. (아직은 정확도 낮다..)\n",
    "# [텐서플로와 차이] For 문에 함께 돌리지 않고, 학습이 끝난 뒤에 Predict 와 Accuracy 측정이 가능\n",
    "# 그러면 대용량 데이터 처리시 메모리 관리는 어떻게 되나?? 계속 누적되어 나아가는 걸까??\n",
    "predicted = (model(X).data > 0.5).float()\n",
    "accuracy = (predicted == Y.data).float().mean()\n",
    "print(\"\\nHypothesis (\", len(hypothesis.data.numpy()),\") :\",hypothesis.data.numpy()[::100], \n",
    "     \"\\nCorrect (\" , len(predicted.numpy()),\")  :\", predicted.numpy()[::100],\n",
    "     \"\\nAccuracy : \" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
